{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HGD - XGBoost.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CZ_tnAl0uw1X",
        "5V37fPRWvBSI",
        "Lls9ssboMBf2",
        "zrnbpSExjda7"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0oL16xi-Kr3"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjdXQ3cu99Z4"
      },
      "source": [
        "#Allows dataset from drive to be utilized\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "## Suppress FutureWarnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m24NpxiS1jr"
      },
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_predict, GridSearchCV, cross_val_score, train_test_split, cross_validate, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, make_scorer, recall_score, precision_score, f1_score, accuracy_score, roc_auc_score, auc, plot_roc_curve\n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from imblearn.pipeline import Pipeline\n",
        "from scipy.stats import mode\n",
        "from sklearn.dummy import DummyClassifier\n",
        "import statistics\n",
        "from imblearn.under_sampling import ClusterCentroids\n",
        "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import permutation_test_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uorMBQ0D-Gd0"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60UsMwbn3whq"
      },
      "source": [
        "#Import DataFrame from .csv file\n",
        "df = pd.read_csv(DATASET_LOCATION)\n",
        "\n",
        "#Creating labels\n",
        "x = df.drop(\"hgd_malignancy\", axis=1); #Entire dataset\n",
        "Y = df[\"hgd_malignancy\"].copy();\n",
        "feature_cols = x.columns\n",
        "\n",
        "#Scale values from 0 to 1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X = scaler.fit_transform(x)\n",
        "print(Y)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=12,test_size=.2,shuffle=True,stratify=Y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVESf1FmjPvK"
      },
      "source": [
        "# Import Strictly Texture Feature Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q02SdpFjD4P"
      },
      "source": [
        "#Import DataFrame from .csv file\n",
        "df = pd.read_csv(DATASET_LOCATION)\n",
        "\n",
        "#Creating labels\n",
        "x = df.drop(\"hgd_malignancy\", axis=1); #Entire dataset\n",
        "Y = df[\"hgd_malignancy\"].copy();\n",
        "feature_cols = x.columns\n",
        "\n",
        "#Scale values from 0 to 1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X = scaler.fit_transform(x)\n",
        "print(Y)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=12,test_size=.2,shuffle=True,stratify=Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBcGWdBdjRfh"
      },
      "source": [
        "# Import Non - Texture Feature Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWVzFYAojELe"
      },
      "source": [
        "#Import DataFrame from .csv file\n",
        "df = pd.read_csv(DATASET_LOCATION)\n",
        "\n",
        "#Creating labels\n",
        "x = df.drop(\"hgd_malignancy\", axis=1); #Entire dataset\n",
        "Y = df[\"hgd_malignancy\"].copy();\n",
        "feature_cols = x.columns\n",
        "\n",
        "#Scale values from 0 to 1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X = scaler.fit_transform(x)\n",
        "print(Y)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=12,test_size=.2,shuffle=True,stratify=Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9eE-X37ilYz"
      },
      "source": [
        "import sys\n",
        "print(sys.version)\n",
        "import sklearn\n",
        "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0u1tHsPrkPy"
      },
      "source": [
        "# Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dta7HM3AgzN2"
      },
      "source": [
        "Best parameters optimized for G-mean (5-fold stratified CV): {'max_depth': 5, 'n_estimators': 9, 'scale_pos_weight': 2.46999999999999}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqwdWbXp-ZNz"
      },
      "source": [
        "# estimate scale_pos_weight value\n",
        "# Here we set the estimate variable to the value of (minority class)/(majority class) \n",
        "# as a starting point for exploring different scale_pos_weight values\n",
        "estimate = 54/26 \n",
        "#54: Negative patients\n",
        "#26: positive patients\n",
        "print('Estimate: %f' % estimate)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4vJPwZbrjl2"
      },
      "source": [
        "# Hyper-parameter Optimization\n",
        "\n",
        "# Hyper-parameter Optimization\n",
        "## Using hyper-parameter optimization, we found the best hyperparameters for\n",
        "## our various models. \n",
        "\n",
        "## The specific hyperparameter values seen throughout the  notebook may not \n",
        "## necessarily be representative of exact hyperparameters used to achieve values\n",
        "##  in manuscript\n",
        "metric=make_scorer(geometric_mean_score)\n",
        "weightlist= np.arange(1, 2, 0.02).tolist()\n",
        "weightlist.append(estimate)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "model = XGBClassifier()\n",
        "\n",
        "# Based on available compute time, set values for each hyperparameter in larger\n",
        "# increments and becoming more granular on subsequent runs as we narrow down\n",
        "# optimal parameter values\n",
        "param_grid = [{'n_estimators': [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40],\n",
        "                  'max_depth': [3,4,5,6,7,8,9,10,11,12],\n",
        "                  'scale_pos_weight': weightlist, # ratio to reverse of ratio with 0.05 in between\n",
        "               }]; \n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=cv, scoring=metric, )\n",
        "grid_search.fit(X, Y)\n",
        "best_model = grid_search.best_estimator_\n",
        "print(grid_search.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SFjCCpobmmo"
      },
      "source": [
        "# Baseline Metrics from Various Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGEpEl4d9zjA"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB1mXtJJ-bIL"
      },
      "source": [
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "Specificities = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold_resample,y_train_fold_resample = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    model = svm.SVC()\n",
        "    model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "    pt = model.predict(X_val_fold)\n",
        "    \n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "    Specificities.append(specificity)\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rdr8Ptw93U_"
      },
      "source": [
        "## Random Forest\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOB_QqmX-jry"
      },
      "source": [
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "Specificities = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold_resample, y_train_fold_resample = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    model = RandomForestClassifier(n_estimators=25,max_depth=20, class_weight='balanced')\n",
        "    model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "    pt = model.predict(X_val_fold)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "    Specificities.append(specificity)\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UKNQcey9-z7"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BozxSlme9Jub"
      },
      "source": [
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "Specificities = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold,y_train_fold = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    model = LogisticRegression(class_weight = \"balanced\")\n",
        "    model.fit(X_train_fold,y_train_fold)\n",
        "    pt = model.predict(X_val_fold)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "    Specificities.append(specificity)\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hFxzWhR9zY1"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6u7MuXIlXqK"
      },
      "source": [
        "### \"Wide\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGtkJVJ--wPm"
      },
      "source": [
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "Specificities = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold_resample,y_train_fold_resample = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    model = MLPClassifier(hidden_layer_sizes=(512, 512, 512), random_state=1)\n",
        "    model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "    pt = model.predict(X_val_fold)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "    Specificities.append(specificity)\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70_OAmByO1xB"
      },
      "source": [
        "# p value \n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, random_state=12, shuffle=True)\n",
        "AUC_metric = make_scorer(roc_auc_score)\n",
        "g_mean_metric = make_scorer(geometric_mean_score)\n",
        "p_values_AUC = {}\n",
        "p_values_g_mean = {}\n",
        "titles = [\"AUC p-value\", \"G-Mean p-value\"]\n",
        "model = MLPClassifier(hidden_layer_sizes=(512, 512, 512), random_state=1, tol = 0.005)\n",
        "\n",
        "_, _, pvalue = permutation_test_score(model, X, Y, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"auc\"] = pvalue\n",
        "print(p_values_AUC)\n",
        "_, _, pvalue = permutation_test_score(model, X, Y, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"gmean\"] = pvalue\n",
        "\n",
        "print(p_values_g_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swkIfJHIlkC6"
      },
      "source": [
        "### \"Deep\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr9XF-uJrj7v"
      },
      "source": [
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "Specificities = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold_resample,y_train_fold_resample = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    model = MLPClassifier(hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100), random_state=1)\n",
        "    model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "    pt = model.predict(X_val_fold)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "    Specificities.append(specificity)\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jtjfj85fNAZA"
      },
      "source": [
        "# p value \n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, random_state=12, shuffle=True)\n",
        "AUC_metric = make_scorer(roc_auc_score)\n",
        "g_mean_metric = make_scorer(geometric_mean_score)\n",
        "p_values_AUC = {}\n",
        "p_values_g_mean = {}\n",
        "titles = [\"AUC p-value\", \"G-Mean p-value\"]\n",
        "model = MLPClassifier(hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100), random_state=1)\n",
        "\n",
        "_, _, pvalue = permutation_test_score(model, X, Y, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"auc\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(model, X, Y, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"gmean\"] = pvalue\n",
        "\n",
        "print(p_values_AUC)\n",
        "print(p_values_g_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1u6FrgBT7Ch"
      },
      "source": [
        "### \"Pyramid\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg7_XABNrk2T"
      },
      "source": [
        "\n",
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "Specificities = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold_resample,y_train_fold_resample = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    model = MLPClassifier(hidden_layer_sizes=(512, 256, 128, 64, 64), random_state=1, max_iter = 400)\n",
        "    model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "    pt = model.predict(X_val_fold)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "    Specificities.append(specificity)\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0Tnkw98OhcU"
      },
      "source": [
        "# p value \n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "cv = StratifiedKFold(n_splits=5, random_state=12, shuffle=True)\n",
        "AUC_metric = make_scorer(roc_auc_score)\n",
        "g_mean_metric = make_scorer(geometric_mean_score)\n",
        "p_values_AUC = {}\n",
        "p_values_g_mean = {}\n",
        "titles = [\"AUC p-value\", \"G-Mean p-value\"]\n",
        "model = MLPClassifier(hidden_layer_sizes=(512, 256, 128, 64, 64), random_state=1, max_iter = 400)\n",
        "_, _, pvalue = permutation_test_score(model, X, Y, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"auc\"] = pvalue\n",
        "\n",
        "print(p_values_AUC)\n",
        "_, _, pvalue = permutation_test_score(model, X, Y, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"gmean\"] = pvalue\n",
        "\n",
        "print(p_values_g_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQJf927w-DyQ"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYJsMAsZsOea"
      },
      "source": [
        "for j in [3,5,7,9,11]:\n",
        "  Precisions = []\n",
        "  Recalls = []\n",
        "  F1s = []\n",
        "  G_means = []\n",
        "  accuracy = []\n",
        "  AUC = []\n",
        "  Specificities = []\n",
        "\n",
        "  for i in range(500):\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "    for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "      X_train_fold_resample,y_train_fold_resample = X[train_fold_index], Y[train_fold_index]\n",
        "      X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "      model = KNeighborsClassifier(n_neighbors=j)\n",
        "\n",
        "      model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "      pt = model.predict(X_val_fold)\n",
        "      tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "      specificity = tn / (tn+fp)\n",
        "      Specificities.append(specificity)\n",
        "      Precisions.append(precision_score(y_val_fold,pt))\n",
        "      Recalls.append(recall_score(y_val_fold,pt))\n",
        "      F1s.append(f1_score(y_val_fold,pt))\n",
        "      G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "      accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "      AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "  print(\"k = \"+ str(j))\n",
        "  print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "  print('Sensitivity/Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "  print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "  print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "  print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "  print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "  print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wM_93EZ_gzG"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gS2PyNWw10z"
      },
      "source": [
        "Precisions = []\n",
        "Recalls = []\n",
        "Specificities = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold,y_train_fold = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    model = XGBClassifier(max_depth=4, n_estimators=5, scale_pos_weight=1.44)\n",
        "    model.fit(X_train_fold,y_train_fold)\n",
        "    pt = model.predict(X_val_fold)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    Specificities.append(tn / (tn+fp))\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision - Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall - Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiOLhjfc_YDL"
      },
      "source": [
        "## XGBoost with Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GdXUFNOdfzI"
      },
      "source": [
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold,y_train_fold = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    model = XGBClassifier(n_estimators=180, max_depth=4, scale_pos_weight=1.5)\n",
        "    model.fit(X_train_fold,y_train_fold)\n",
        "    pt = model.predict(X_val_fold)\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %f Standard Deviation: %f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Recall- Mean:  %f Standard Deviation: %f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('F1- Mean:  %f Standard Deviation: %f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %f Standard Deviation: %f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %f Standard Deviation: %f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %f Standard Deviation: %f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSf2DvzPY6WR"
      },
      "source": [
        "## XGBoost with Oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDvTCHbIL6wf"
      },
      "source": [
        "### SMOTE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CHpgVin33Kg"
      },
      "source": [
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "Specificities = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold,y_train_fold = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    smoter = SMOTE()\n",
        "    X_train_fold_resample, y_train_fold_resample = smoter.fit_resample(X_train_fold,y_train_fold)\n",
        "    model = XGBClassifier(max_depth=5, n_estimators=9, scale_pos_weight=2.47)\n",
        "    model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "    pt = model.predict(X_val_fold)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "    Specificities.append(specificity)\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jxxkgaz6WZ3"
      },
      "source": [
        "### Random Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQHrsMKnXtwJ"
      },
      "source": [
        "Precisons = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold,y_train_fold = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    ros3 = RandomOverSampler(random_state=0)\n",
        "    X_train_fold_resample, y_train_fold_resample = ros3.fit_resample(X_train_fold,y_train_fold)\n",
        "    model = XGBClassifier(n_estimators=9, max_depth=5, scale_pos_weight= 2.47)\n",
        "    model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "    pt = model.predict(X_val_fold)\n",
        "\n",
        "    Precisons.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPSZdC4pouuN"
      },
      "source": [
        "# Naive Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC5SaeR5MlzQ"
      },
      "source": [
        "## Majority Classifier Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1m6soupM54z",
        "outputId": "39977f8e-a7f7-4905-82a1-4f7839fa8c62"
      },
      "source": [
        "# Naive Classifier \n",
        "## Predicts the Majority (Mucinous) Class\n",
        "## Source: https://machinelearningmastery.com/how-to-develop-and-evaluate-naive-classifier-strategies-using-probability/\n",
        "##         https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics \n",
        "\n",
        "from scipy.stats import mode\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score,accuracy_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "\n",
        "# predict the majority class\n",
        "def majority_class(y):\n",
        "\treturn mode(Y)[0]\n",
        "\n",
        "# make predictions\n",
        "yhat = [0 for _ in range(len(Y))]\n",
        "print(yhat)\n",
        "tn, fp, fn, tp = confusion_matrix(Y, yhat).ravel()\n",
        "\n",
        "# calculate Metrics\n",
        "print('F1 : %.3f' % f1_score(Y, yhat))\n",
        "print('Recall : %.3f' % recall_score(Y,yhat))\n",
        "print('Specificity :  %.3f' % (tn/(tn+fp)))\n",
        "print('Precision : %.3f' % precision_score(Y,yhat))\n",
        "print('G-Mean : %.3f' % geometric_mean_score(Y,yhat))\n",
        "print('accuracy : %.3f' % accuracy_score(Y,yhat))\n",
        "print('AUC:  %.3f' % roc_auc_score(Y,yhat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "F1 : 0.000\n",
            "Recall : 0.000\n",
            "Specificity :  1.000\n",
            "Precision : 0.000\n",
            "G-Mean : 0.000\n",
            "accuracy : 0.675\n",
            "AUC:  0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1FNR9Gpb3CL"
      },
      "source": [
        "## Minority Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "matJ-7UccBkp",
        "outputId": "ade176c3-65d8-42a6-b501-318b4985e4a5"
      },
      "source": [
        "# Naive Classifier \n",
        "## Predicts the Majority (Mucinous) Class\n",
        "## Source: https://machinelearningmastery.com/how-to-develop-and-evaluate-naive-classifier-strategies-using-probability/\n",
        "##         https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics \n",
        "\n",
        "\n",
        "# predict the majority class\n",
        "def majority_class(Y):\n",
        "\treturn mode(y)[0]\n",
        "\n",
        "# make predictions\n",
        "yhat = [1 for _ in range(len(Y))] #Hardcoded for our model's distribution\n",
        "print(yhat)\n",
        "tn, fp, fn, tp = confusion_matrix(Y, yhat).ravel()\n",
        "\n",
        "# calculate Metrics\n",
        "print('F1 : %.3f' % f1_score(Y, yhat))\n",
        "print('Recall/sensitivity : %.3f' % recall_score(Y,yhat))\n",
        "print('Specificity :  %.3f' % (tn/(tn+fp)))\n",
        "print('Precision : %.3f' % precision_score(Y,yhat))\n",
        "print('G-Mean : %.3f' % geometric_mean_score(Y,yhat))\n",
        "print('accuracy : %.3f' % accuracy_score(Y,yhat))\n",
        "print('AUC:  %.3f' % roc_auc_score(Y,yhat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "F1 : 0.491\n",
            "Recall/sensitivity : 1.000\n",
            "Specificity :  0.000\n",
            "Precision : 0.325\n",
            "G-Mean : 0.000\n",
            "accuracy : 0.325\n",
            "AUC:  0.500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq08zkQcb3Ni"
      },
      "source": [
        "## Random Guesser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LFUVOvkcBGO",
        "outputId": "ee853b33-f6b2-4877-9d83-cc92e8e5be83"
      },
      "source": [
        "dummy_clf = DummyClassifier(strategy=\"uniform\")\n",
        "dummy_clf.fit(X, Y)\n",
        "y_predicted = dummy_clf.predict(X)\n",
        "\n",
        "f1= []\n",
        "rcll = []\n",
        "prc = []\n",
        "gmean = []\n",
        "acc = []\n",
        "spec = []\n",
        "roc = []\n",
        "\n",
        "for i in range(10000):\n",
        "  y_predicted = dummy_clf.predict(X)\n",
        "  f1.append(f1_score(Y, y_predicted))\n",
        "  rcll.append(recall_score(Y,y_predicted))\n",
        "  prc.append(precision_score(Y,y_predicted))\n",
        "  gmean.append(geometric_mean_score(Y,y_predicted))\n",
        "  acc.append(accuracy_score(Y,y_predicted))\n",
        "  tn, fp, fn, tp = confusion_matrix(Y, y_predicted).ravel()\n",
        "  spec.append(tn/(tn+fp))\n",
        "  roc.append(roc_auc_score(Y,y_predicted))\n",
        "\n",
        "print('Precision - Mean:  %.3f Standard Deviation: %.3f' % (mean(prc), statistics.pstdev(prc)))\n",
        "print('Sensitivity/Recall - Mean:  %.3f Standard Deviation: %.3f' % (mean(rcll), statistics.pstdev(rcll)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(spec), statistics.pstdev(spec)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(f1), statistics.pstdev(f1)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(gmean), statistics.pstdev(gmean)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(acc), statistics.pstdev(acc)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(roc), statistics.pstdev(roc)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision - Mean:  0.325 Standard Deviation: 0.053\n",
            "Sensitivity/Recall - Mean:  0.500 Standard Deviation: 0.098\n",
            "Specificity - Mean:  0.501 Standard Deviation: 0.068\n",
            "F1- Mean:  0.393 Standard Deviation: 0.066\n",
            "G_mean- Mean:  0.497 Standard Deviation: 0.060\n",
            "Accuracy- Mean:  0.501 Standard Deviation: 0.056\n",
            "AUC Score- Mean:  0.500 Standard Deviation: 0.060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlY6izqD_DNJ"
      },
      "source": [
        "#ALL model Pvalues\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKh8FiQjtiMo"
      },
      "source": [
        "## P values for various models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDU7_oEK_Gtm"
      },
      "source": [
        "## Full Feature Set\n",
        "df = pd.read_csv(DATASET_LOCATION)\n",
        "x_texture = df.drop(\"hgd_malignancy\", axis=1);\n",
        "Y_texture = df[\"hgd_malignancy\"].copy();\n",
        "feature_cols = x_texture.columns\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_texture = scaler.fit_transform(x_texture)\n",
        "\n",
        "## Non-texture only Feature Set\n",
        "df = pd.read_csv(DATASET_LOCATION)\n",
        "x_combined = df.drop(\"hgd_malignancy\", axis=1);\n",
        "Y_combined  = df[\"hgd_malignancy\"].copy();\n",
        "feature_cols = x_combined.columns\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_combined = scaler.fit_transform(x_combined)\n",
        "\n",
        "# Models\n",
        "linear = LogisticRegression(class_weight = \"balanced\")\n",
        "svc = svm.SVC()\n",
        "rf = RandomForestClassifier(n_estimators=25,max_depth=20, class_weight='balanced')\n",
        "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
        "knn5 = KNeighborsClassifier(n_neighbors=5)\n",
        "knn7 = KNeighborsClassifier(n_neighbors=7)\n",
        "knn9 = KNeighborsClassifier(n_neighbors=9)\n",
        "knn11 = KNeighborsClassifier(n_neighbors=11)\n",
        "\n",
        "## Setup\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "AUC_metric = make_scorer(roc_auc_score)\n",
        "g_mean_metric = make_scorer(geometric_mean_score)\n",
        "p_values_AUC = {}\n",
        "p_values_g_mean = {}\n",
        "titles = [\"AUC p-value\", \"G-Mean p-value\"]\n",
        "\n",
        "## AUC\n",
        "_, _, pvalue = permutation_test_score(linear, X_combined, Y_combined, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"linear\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(svc, X_combined, Y_combined, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"svc\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(knn3, X_combined, Y_combined, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"knn3\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(knn5, X_combined, Y_combined, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"knn5\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(knn7, X_combined, Y_combined, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"knn7\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(knn9, X_combined, Y_combined, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"knn9\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(knn11, X_combined, Y_combined, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"knn11\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(rf, X_combined, Y_combined, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"rf\"] = pvalue\n",
        "\n",
        "# G - Mean\n",
        "_, _, pvalue = permutation_test_score(linear, X_combined, Y_combined, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"linear\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(svc, X_combined, Y_combined, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"svc\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(knn3, X_combined, Y_combined, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"knn3\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(knn5, X_combined, Y_combined, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"knn5\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(knn7, X_combined, Y_combined, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"knn7\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(knn9, X_combined, Y_combined, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"knn9\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(knn11, X_combined, Y_combined, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"knn11\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(rf, X_combined, Y_combined, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"rf\"] = pvalue\n",
        "\n",
        "# Output Table\n",
        "print(\"AUC\")\n",
        "print(p_values_AUC)\n",
        "print(\"G-Mean\")\n",
        "print(p_values_g_mean)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY9D46ktt0x8"
      },
      "source": [
        "## P values for XGBoost and Naive classifiers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltkWN3Ywstzq"
      },
      "source": [
        "# Datasets\n",
        "## Full Feature Set\n",
        "df = pd.read_csv(DATASET_LOCATION)\n",
        "x_full = df.drop(\"hgd_malignancy\", axis=1); #Entire dataset\n",
        "Y_full = df[\"hgd_malignancy\"].copy()\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_full = scaler.fit_transform(x_full)\n",
        "\n",
        "#Import Texture-Only Feature Set\n",
        "df = pd.read_csv(DATASET_LOCATION)\n",
        "x_texture = df.drop(\"hgd_malignancy\", axis=1); #Entire dataset\n",
        "Y_texture = df[\"hgd_malignancy\"].copy();\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_texture = scaler.fit_transform(x_texture)\n",
        "\n",
        "# Models\n",
        "## Naive\n",
        "## Majority, Minority, random, stratified\n",
        "majority = DummyClassifier(strategy='constant', constant=1) #strategy='most_frequent'\n",
        "minority = DummyClassifier(strategy='constant', constant=0)\n",
        "random = DummyClassifier(strategy='uniform', constant=1)\n",
        "stratified = DummyClassifier(strategy='stratified', constant=1)\n",
        "random.fit(X_full, Y_full)\n",
        "stratified.fit(X_full, Y_full)\n",
        "\n",
        "## ML\n",
        "## SMOTE Full Feature, SMOTE Texture-Only, XGBoost Full, XGBoost Texture-only\n",
        "XGBoost = XGBClassifier(n_estimators=11, max_depth=3, scale_pos_weight=.25)\n",
        "SMOTE_XGBoost = Pipeline([\n",
        "        ('sampling', SMOTE()),\n",
        "        ('classification', XGBoost)\n",
        "    ])\n",
        "\n",
        "# Scoring\n",
        "## Setup\n",
        "cv = StratifiedKFold(n_splits=5, random_state=12, shuffle=True)\n",
        "AUC_metric = make_scorer(roc_auc_score)\n",
        "g_mean_metric = make_scorer(geometric_mean_score)\n",
        "p_values_AUC = {}\n",
        "p_values_g_mean = {}\n",
        "titles = [\"AUC p-value\", \"G-Mean p-value\"]\n",
        "\n",
        "## AUC\n",
        "_, _, pvalue = permutation_test_score(majority, X_full, Y_full, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"majority\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(minority, X_full, Y_full, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"minority\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(random, X_full, Y_full, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"random\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(stratified, X_full, Y_full, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"stratified\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(XGBoost, X_full, Y_full, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"XGBoost_Full\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(SMOTE_XGBoost, X_full, Y_full, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"SMOTE_Full\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(XGBoost, X_texture, Y_texture, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"XGBoost_Texture\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(SMOTE_XGBoost, X_texture, Y_texture, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"SMOTE_Texture\"] = pvalue\n",
        "\n",
        "## G - Mean\n",
        "_, _, pvalue = permutation_test_score(majority, X_full, Y_full, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"majority\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(minority, X_full, Y_full, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"minority\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(random, X_full, Y_full, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"random\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(stratified, X_full, Y_full, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"stratified\"] = pvalue\n",
        "score, _, pvalue = permutation_test_score(XGBoost, X_full, Y_full, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"XGBoost_Full\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(SMOTE_XGBoost, X_full, Y_full, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"SMOTE_Full\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(XGBoost, X_texture, Y_texture, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"XGBoost_Texture\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(SMOTE_XGBoost, X_texture, Y_texture, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"SMOTE_Texture\"] = pvalue\n",
        "\n",
        "# Output Table\n",
        "print(\"AUC\")\n",
        "print(p_values_AUC)\n",
        "print(\"G-Mean\")\n",
        "print(p_values_g_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50SDuqQx0Tel"
      },
      "source": [
        "# Curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg-vk0JJ0RT2"
      },
      "source": [
        "## PR Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76fcAAT6wCy4"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "from numpy import interp\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "FOLDS = 10\n",
        "\n",
        "f, axes = plt.subplots(figsize=(10,10))\n",
        "k_fold = StratifiedKFold(n_splits=FOLDS, random_state=12, shuffle=True)\n",
        "results = pd.DataFrame(columns=['training_score', 'test_score'])\n",
        "\n",
        "\n",
        "y_realtot = []\n",
        "y_probatot = []\n",
        "\n",
        "precision_arraytot = []\n",
        "threshold_arraytot=[]\n",
        "recall_arraytot = np.linspace(0, 1, 100)\n",
        "\n",
        "for j in range(10):\n",
        "  y_real = []\n",
        "  y_proba = []\n",
        "\n",
        "  precision_array = []\n",
        "  threshold_array=[]\n",
        "  recall_array = np.linspace(0, 1, 100)\n",
        "  for i, (train_index, test_index) in enumerate(k_fold.split(X,Y)):\n",
        "    predictor = XGBClassifier(n_estimators=45, max_depth=4, scale_pos_weight=55)\n",
        "      \n",
        "    X_train_fold,y_train_fold = X[train_index], Y[train_index]\n",
        "    X_val_fold, y_val_fold = X[test_index], Y[test_index]\n",
        "    smoter = SMOTE(random_state=12)\n",
        "    X_train_fold_resample, y_train_fold_resample = smoter.fit_resample(X_train_fold,y_train_fold)\n",
        "      \n",
        "    predictor.fit(X_train_fold_resample, y_train_fold_resample)\n",
        "    pred_proba = predictor.predict_proba(X_val_fold)\n",
        "    precision_fold, recall_fold, thresh = precision_recall_curve(y_val_fold, pred_proba[:,1])\n",
        "    precision_fold, recall_fold, thresh = precision_fold[::-1], recall_fold[::-1], thresh[::-1]  # reverse order of results\n",
        "    thresh = np.insert(thresh, 0, 1.0)\n",
        "    precision_array = interp(recall_array, recall_fold, precision_fold)\n",
        "    threshold_array = interp(recall_array, recall_fold, thresh)\n",
        "    pr_auc = auc(recall_array, precision_array)\n",
        "\n",
        "    lab_fold = 'Fold %d AUC=%.4f' % (i+1, pr_auc)\n",
        "    y_real.append(y_val_fold)\n",
        "    y_proba.append(pred_proba[:,1])\n",
        "\n",
        "  y_real = numpy.concatenate(y_real)\n",
        "  y_proba = numpy.concatenate(y_proba)\n",
        "  precision, recall, _ = precision_recall_curve(y_real, y_proba)\n",
        "  lab_foldtot = 'PR %d AUC=%.4f' % (j+1, pr_auc)\n",
        "  plt.plot(recall, precision, marker='.' ,alpha=0.3, label=lab_foldtot)\n",
        "  y_realtot.append(y_real)\n",
        "  y_probatot.append(y_proba)\n",
        "  precision_arraytot = interp(recall_array, recall, precision)\n",
        "  threshold_arraytot = interp(recall_array, recall, precision)\n",
        "\n",
        "#finsih 10 iterations.\n",
        "y_realtot = numpy.concatenate(y_realtot)\n",
        "y_probatot= numpy.concatenate(y_probatot)\n",
        "precision, recall, _ = precision_recall_curve(y_realtot, y_probatot)\n",
        "lab = 'Overall AUC=%.4f' % (auc(recall, precision))\n",
        "\n",
        "plt.plot(recall, precision, marker='.', lw=2,color='red', label=lab)\n",
        "plt.legend(loc='lower left', fontsize=18)\n",
        "\n",
        "lab = 'Overall AUC=%.4f' % (auc(recall, precision))\n",
        "mean_precision = np.mean(precision)\n",
        "mean_recall = np.mean(recall)\n",
        "std_precision = np.std(precision)\n",
        "print (\"mean of precision: \" )\n",
        "print (mean_precision )\n",
        "\n",
        "print (\"Std Dev of precision: \")\n",
        "print ( std_precision )\n",
        "\n",
        "axes.set_title('10 Indenpendent PR Curves of Random Forest Over 10 Folds Cross Validation', fontsize=18)\n",
        "\n",
        "plt.fill_between(recall, precision + std_precision, precision - std_precision, alpha=0.3, linewidth=0, color='grey')\n",
        "plt.xlabel(\"Recall\", fontsize=18)\n",
        "plt.ylabel(\"Precision\", fontsize=18)\n",
        "plt.ylim((0,1))\n",
        "plt.xlim((0,1))\n",
        "plt.show()\n",
        "\n",
        "f.savefig('result.png')\n",
        "print (precision)\n",
        "print (recall)\n",
        "print (_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rhGEp140nYK"
      },
      "source": [
        "## ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-RpAgWplpXf"
      },
      "source": [
        " ## ROC Curve for 10-Fold Cross Validation with SMOTE oversampling \n",
        " # Source: https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/auto_examples/plot_roc_crossval.html\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import plot_roc_curve\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# #############################################################################\n",
        "# Run classifier with cross-validation and plot ROC curves\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, random_state=12, shuffle=True)\n",
        "plt.rcParams[\"figure.figsize\"] = [14,10]\n",
        "tprs = []\n",
        "aucs = []\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "fig, ax = plt.subplots()\n",
        "for i, (train_fold_index, val_fold_index) in enumerate(cv.split(X, Y)):\n",
        "  X_train_fold,y_train_fold = X[train_fold_index], Y[train_fold_index]\n",
        "  X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "  smoter = SMOTE(random_state=12)\n",
        "  X_train_fold_resample, y_train_fold_resample = smoter.fit_resample(X_train_fold,y_train_fold)\n",
        "  classifier =XGBClassifier(n_estimators=9, max_depth=5, scale_pos_weight=2.47)\n",
        "\n",
        "  classifier.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "  viz = plot_roc_curve(classifier, X[val_fold_index], Y[val_fold_index],\n",
        "                         name='ROC fold {}'.format(i+1),\n",
        "                         alpha=0.3, lw=1, ax=ax)\n",
        "  interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
        "  interp_tpr[0] = 0.0\n",
        "  tprs.append(interp_tpr)\n",
        "  aucs.append(viz.roc_auc)\n",
        "\n",
        "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
        "        label='Chance', alpha=.8)\n",
        "\n",
        "mean_tpr = np.mean(tprs, axis=0)\n",
        "mean_tpr[-1] = 1.0\n",
        "mean_auc = auc(mean_fpr, mean_tpr)\n",
        "std_auc = np.std(aucs)\n",
        "ax.plot(mean_fpr, mean_tpr, color='b',\n",
        "        label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
        "        lw=2, alpha=.8)\n",
        "\n",
        "std_tpr = np.std(tprs, axis=0)\n",
        "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
        "                label=r'$\\pm$ 1 std. dev.')\n",
        "\n",
        "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
        "       title=\"Receiver operating characteristic\")\n",
        "ax.legend(loc=\"lower right\")\n",
        "\n",
        "plt.savefig(\"roc.jpg\", dpi=300)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZcruW42OzVH"
      },
      "source": [
        "n_classes = np.unique(Y).size\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, random_state=12, shuffle=True)\n",
        "xgb =  XGBClassifier(n_estimators=32, max_depth=3, scale_pos_weight=.2875)\n",
        "metric=make_scorer(geometric_mean_score)\n",
        "\n",
        "model = Pipeline([\n",
        "        ('sampling', SMOTE(random_state=12)),\n",
        "        ('classification', xgb)\n",
        "    ])\n",
        "\n",
        "score, permutation_scores, pvalue = permutation_test_score(\n",
        "    model,X, Y, scoring=metric, cv=cv, n_permutations=1000)\n",
        "\n",
        "print(\"Classification score %s (pvalue : %s)\" % (score, pvalue))\n",
        "\n",
        "## ROC Curve for 10-Fold Cross Validation with SMOTE oversampling \n",
        " # Source: https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/auto_examples/plot_roc_crossval.html\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import plot_roc_curve\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# #############################################################################\n",
        "# Run classifier with cross-validation and plot ROC curves\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, random_state=12, shuffle=True)\n",
        "plt.rcParams[\"figure.figsize\"] = [14,10]\n",
        "tprs = []\n",
        "aucs = []\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "fig, ax = plt.subplots()\n",
        "for i, (train_fold_index, val_fold_index) in enumerate(cv.split(X, Y)):\n",
        "  X_train_fold,y_train_fold = X[train_fold_index], Y[train_fold_index]\n",
        "  X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "  smoter = SMOTE(random_state=12)\n",
        "  X_train_fold_resample, y_train_fold_resample = smoter.fit_resample(X_train_fold,y_train_fold)\n",
        "  classifier =XGBClassifier(n_estimators=32, max_depth=3, scale_pos_weight=.2875)\n",
        "  classifier.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "  viz = plot_roc_curve(classifier, X[val_fold_index], Y[val_fold_index],\n",
        "                         name='ROC fold {}'.format(i+1),\n",
        "                         alpha=0.3, lw=1, ax=ax)\n",
        "  interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
        "  interp_tpr[0] = 0.0\n",
        "  tprs.append(interp_tpr)\n",
        "  aucs.append(viz.roc_auc)\n",
        "\n",
        "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
        "        label='Chance', alpha=.8)\n",
        "\n",
        "mean_tpr = np.mean(tprs, axis=0)\n",
        "mean_tpr[-1] = 1.0\n",
        "mean_auc = auc(mean_fpr, mean_tpr)\n",
        "std_auc = np.std(aucs)\n",
        "ax.plot(mean_fpr, mean_tpr, color='b',\n",
        "        label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
        "        lw=2, alpha=.8)\n",
        "\n",
        "std_tpr = np.std(tprs, axis=0)\n",
        "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
        "                label=r'$\\pm$ 1 std. dev.')\n",
        "\n",
        "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
        "       title=\"Receiver operating characteristic\")\n",
        "ax.legend(loc=\"lower right\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLkq9_6UaV2v"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Permutation Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90irGYfqfuVm"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import permutation_test_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "#Uses test 1 described here:\n",
        "# http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf\n",
        "\n",
        "# #############################################################################\n",
        "n_classes = np.unique(Y).size\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, random_state=12, shuffle=True)\n",
        "xgb =  XGBClassifier(n_estimators=9, max_depth=5, scale_pos_weight=2.47)\n",
        "metric=make_scorer(geometric_mean_score)\n",
        "\n",
        "score, permutation_scores, pvalue = permutation_test_score(\n",
        "    xgb,X, Y, scoring=metric, cv=cv, n_permutations=1000)\n",
        "\n",
        "print(\"Classification score %s (pvalue : %s)\" % (score, pvalue))\n",
        "\n",
        "# #############################################################################\n",
        "# View histogram of permutation scores\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.hist(permutation_scores, 20, label='Permutation scores',\n",
        "         edgecolor='black')\n",
        "ylim = plt.ylim()\n",
        "\n",
        "plt.plot(2 * [score], ylim, '--g', linewidth=3,\n",
        "         label='Classification Score')\n",
        "plt.plot(2 * [1. /n_classes], ylim, '--k', linewidth=3, label='Luck')\n",
        "plt.ylim(ylim)\n",
        "plt.legend()\n",
        "plt.xlabel('Score')\n",
        "plt.savefig(\"ptest.jpg\", dpi=300)\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwyOGmkpc9TW"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vTyPWligzAS"
      },
      "source": [
        "# most improtant feature function\n",
        "def Important_fetures(mymodel,featuredict):\n",
        "    import numpy as np\n",
        "    import sklearn as sk\n",
        "    import sklearn.datasets as skd\n",
        "    import matplotlib.pyplot as plt\n",
        "    %matplotlib inline\n",
        "\n",
        "    importances = model.feature_importances_\n",
        "\n",
        "    indice = np.argsort(importances)[::-1]\n",
        "\n",
        "    indices = indice [:30]\n",
        "\n",
        "    # Print the feature ranking\n",
        "    num=0\n",
        "    with open(\"/content/drive/My Drive/CT Analysis/Saved Data/Important Features/XGBoost2.txt\", \"w\") as txt_file:\n",
        "      for f in indices:\n",
        "        indexname = f;\n",
        "        num+=1;\n",
        "        if feature_cols[indexname] in featuredict:\n",
        "          featuredict[feature_cols[indexname]][0] += 1\n",
        "          featuredict[feature_cols[indexname]][1] += importances[indexname]\n",
        "        else:\n",
        "          featuredict[feature_cols[indexname]] = [1,importances[indexname]]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylZcoJlLgzDE"
      },
      "source": [
        "featuredict = {}\n",
        "\n",
        "for x in range(0,1000):\n",
        "\n",
        "        cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "        Precisons = []\n",
        "        Recalls = []\n",
        "        F1s = []\n",
        "        G_means = []\n",
        "\n",
        "        for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "          X_train_fold,y_train_fold = X[train_fold_index], Y[train_fold_index]\n",
        "          X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "          smoter = SMOTE()\n",
        "          X_train_fold_resample, y_train_fold_resample = smoter.fit_resample(X_train_fold,y_train_fold)\n",
        "          model = XGBClassifier(n_estimators=9, max_depth=5, scale_pos_weight=2.47)\n",
        "          model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "          pt = model.predict(X_val_fold)\n",
        "\n",
        "          Important_fetures(model,featuredict)\n",
        "\n",
        "          Precisons.append(precision_score(y_val_fold,pt))\n",
        "          Recalls.append(recall_score(y_val_fold,pt))\n",
        "          F1s.append(f1_score(y_val_fold,pt))\n",
        "          G_means.append(geometric_mean_score(y_val_fold,pt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vd8WAEWgzFp"
      },
      "source": [
        "#List ranked by average\n",
        "import operator\n",
        "import collections\n",
        "\n",
        "Avg = {}\n",
        "Ocurr = {}\n",
        "Tavg ={}\n",
        "for key in featuredict:\n",
        "  Avg[key] = [featuredict[key][1]/featuredict[key][0],featuredict[key][0]]\n",
        "  Ocurr[key] = featuredict[key][0]\n",
        "  Tavg[key] =  featuredict[key][1]/5000\n",
        "\n",
        "AvgRank = sorted(Avg.items(),key=lambda kv: kv[1][0],reverse=True)\n",
        "OcurrRank = sorted(Ocurr.items(),key=lambda x: x[1],reverse=True)\n",
        "TavRank = sorted(Tavg.items(),key=lambda kv: kv[1],reverse=True)\n",
        "\n",
        "sortedAvg = {}\n",
        "for i in AvgRank:\n",
        "  sortedAvg[i[0]] = [i[1][0],i[1][1]]\n",
        "\n",
        "\n",
        "\n",
        "Ocuurpd = pd.DataFrame.from_dict(OcurrRank)\n",
        "Avgdf = pd.DataFrame.from_dict(sortedAvg,orient='index',columns=['Avg.Value','Occurance'])\n",
        "Tavdf = pd.DataFrame.from_dict(TavRank)\n",
        "Ocuurpd.columns = ['Feature', 'Avg. Value']\n",
        "Avgdf.to_csv('Average featuer Importance-hgd.CSV');\n",
        "Ocuurpd.to_csv('Ocuurance-hgd.CSV')\n",
        "Tavdf.to_csv('TSC-hgd.CSV')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE5aWmcQgzHz"
      },
      "source": [
        "a = 0 \n",
        "df2 = df\n",
        "for (columnName, columnData) in df.iteritems():\n",
        "  if columnName not in Avg:\n",
        "    a +=1\n",
        "    df2 = df2.drop(columnName, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpUcD1IfgzJr"
      },
      "source": [
        "#Creating labels\n",
        "\n",
        "x1 = df2\n",
        "Y = df[\"hgd_malignancy\"].copy();\n",
        "feature_cols = x1.columns\n",
        "\n",
        "#Scale values from 0 to 1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X1 = scaler.fit_transform(x1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k8FIL6agzMk"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=5, random_state=12, shuffle=True)\n",
        "\n",
        "Precisons = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "\n",
        "\n",
        "for train_fold_index, val_fold_index in cv.split(X1,Y):\n",
        "  X_train_fold,y_train_fold = X1[train_fold_index], Y[train_fold_index]\n",
        "  X_val_fold, y_val_fold = X1[val_fold_index], Y[val_fold_index]\n",
        "  smoter = SMOTE(random_state=12)\n",
        "  X_train_fold_resample, y_train_fold_resample = smoter.fit_resample(X_train_fold,y_train_fold)\n",
        "  model = XGBClassifier(n_estimators=9, max_depth=5, scale_pos_weight=2.47)\n",
        "  model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "  pt = model.predict(X_val_fold)\n",
        "\n",
        "  print(\"confusion_matrix:\")\n",
        "  print(confusion_matrix(y_val_fold,pt))\n",
        "  Precisons.append(precision_score(y_val_fold,pt))\n",
        "  Recalls.append(recall_score(y_val_fold,pt))\n",
        "  F1s.append(f1_score(y_val_fold,pt))\n",
        "  G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "  accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision: ',mean(Precisons))\n",
        "print('Recall: ',mean(Recalls))\n",
        "print('F1: ',mean(F1s))\n",
        "print('G_mean: ',mean(G_means))\n",
        "print('Accuracy: ',mean(accuracy))\n",
        "print(AvgRank)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}