{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of New Models and Metrics - XGBoost - Imbalanced Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "v0oL16xi-Kr3",
        "uorMBQ0D-Gd0",
        "eNhKrcWN5hAQ",
        "kcFue018CGpC",
        "TnJX8JkZDoWz",
        "F0u1tHsPrkPy",
        "n1G4UA9j1wxi",
        "MIFVaE1d1w84",
        "WlKvv6QZ1xFx",
        "8zpEHpZr2OWL",
        "47MNyx1Iq42W",
        "yz4JuqMr7ocj",
        "ASJWSwCZq4pe",
        "JlToU7rDlbKP",
        "9SFjCCpobmmo",
        "fC5SaeR5MlzQ",
        "Z1FNR9Gpb3CL",
        "Gq08zkQcb3Ni",
        "DUvop-yJoPBF",
        "uiOLhjfc_YDL",
        "1572MnVE_WWk",
        "50SDuqQx0Tel",
        "Wg-vk0JJ0RT2",
        "-rhGEp140nYK",
        "gBkqr3kjHyas",
        "wLkq9_6UaV2v",
        "OwyOGmkpc9TW",
        "8OladWpGS9K2",
        "esGSHENVSqT1",
        "gu9QM6V7S64A",
        "zrnbpSExjda7",
        "3i8s_N-oWmuW"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0oL16xi-Kr3"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjdXQ3cu99Z4"
      },
      "source": [
        "#Allows dataset from drive to be utilized\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlPQScgc6j5y"
      },
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_predict, GridSearchCV, cross_val_score, train_test_split, cross_validate, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, make_scorer, recall_score, precision_score, f1_score, accuracy_score, roc_auc_score, auc, plot_roc_curve\n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from imblearn.pipeline import Pipeline\n",
        "from scipy.stats import mode\n",
        "from sklearn.dummy import DummyClassifier\n",
        "import statistics\n",
        "from imblearn.under_sampling import ClusterCentroids\n",
        "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import permutation_test_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6qI5W4DiB-E"
      },
      "source": [
        "import imblearn\n",
        "print('imblearn: {}'.format(imblearn.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uorMBQ0D-Gd0"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60UsMwbn3whq"
      },
      "source": [
        "#Import DataFrame from .csv file\n",
        "df = pd.read_csv(DATASET_LOCATION)\n",
        "\n",
        "#Creating labels\n",
        "x = df.drop(\"mucinous\", axis=1); #Entire dataset\n",
        "Y = df[\"mucinous\"].copy();\n",
        "feature_cols = x.columns\n",
        "\n",
        "#Scale values from 0 to 1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X = scaler.fit_transform(x)\n",
        "print(X.shape)\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=12,test_size=.2,shuffle=True,stratify=Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JpGkij7ikYv"
      },
      "source": [
        "import sys\n",
        "print(sys.version)\n",
        "import sklearn\n",
        "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNhKrcWN5hAQ"
      },
      "source": [
        "## Import Strictly Texture Feature Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owk828Gj5gUg"
      },
      "source": [
        "#Import DataFrame from .csv file\n",
        "df = pd.read_csv(DATASET_LOCATION)\n",
        "\n",
        "#Creating labels\n",
        "x = df.drop(\"mucinous\", axis=1); #Entire dataset\n",
        "Y = df[\"mucinous\"].copy();\n",
        "feature_cols = x.columns\n",
        "\n",
        "#Scale values from 0 to 1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X = scaler.fit_transform(x)\n",
        "print(X.shape)\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=12,test_size=.2,shuffle=True,stratify=Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcFue018CGpC"
      },
      "source": [
        "## Import Non - Texture Feature Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuf6KYcfCGYi"
      },
      "source": [
        "#Import DataFrame from .csv file\n",
        "df = pd.read_csv(DATASET_LOCATION)\n",
        "\n",
        "#Creating labels\n",
        "x = df.drop(\"mucinous\", axis=1); #Entire dataset\n",
        "Y = df[\"mucinous\"].copy();\n",
        "feature_cols = x.columns\n",
        "\n",
        "#Scale values from 0 to 1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X = scaler.fit_transform(x)\n",
        "print(X.shape)\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=12,test_size=.2,shuffle=True,stratify=Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0u1tHsPrkPy"
      },
      "source": [
        "# Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp_hxdkCWU60"
      },
      "source": [
        "Full Feature Set Hyperparameters (5 Stratified CV): depth = 3, estimators = 11, weight scale = "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqwdWbXp-ZNz"
      },
      "source": [
        "# estimate scale_pos_weight value\n",
        "estimate = 1/1 # Here we set the estimate variable to the value of (minority class)/(majority class) as a starting point for\n",
        "                # exploring different scale_pos_weight values\n",
        "print('Estimate: %.3f' % estimate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4vJPwZbrjl2"
      },
      "source": [
        "# Hyper-parameter Optimization\n",
        "## Using hyper-parameter optimization, we found the best hyperparameters for\n",
        "## our various models. \n",
        "\n",
        "## The specific hyperparameter values seen throughout the  notebook may not \n",
        "## necessarily be representative of exact hyperparameters used to achieve values\n",
        "##  in manuscript\n",
        "\n",
        "metric=make_scorer(roc_auc_score)\n",
        "weightlist= np.arange(.1, .4, 0.05).tolist()\n",
        "weightlist.append(estimate)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "model = XGBClassifier()\n",
        "\n",
        "# Based on available compute time, set values for each hyperparameter in larger\n",
        "# increments and becoming more granular on subsequent runs as we narrow down\n",
        "# optimal parameter values\n",
        "param_grid = [{'n_estimators': [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30],\n",
        "                  'max_depth': [3,4,5,6],\n",
        "                  'scale_pos_weight': weightlist,\n",
        "               }]\n",
        "grid_search = GridSearchCV(model, param_grid, cv=cv, scoring=metric, )\n",
        "grid_search.fit(X, Y)\n",
        "best_model = grid_search.best_estimator_\n",
        "print(grid_search.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK2sCkuv1tPd"
      },
      "source": [
        "# Baseline Metrics from Various Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1G4UA9j1wxi"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbxwPxKD2Int"
      },
      "source": [
        "## Metrics \n",
        "# K-fold\n",
        "from statistics import mean as mean\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "Specificities = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold_resample, y_train_fold_resample = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    model = RandomForestClassifier(n_estimators=8,max_depth=9)\n",
        "    model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "    pt = model.predict(X_val_fold)\n",
        "    \n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "    Specificities.append(specificity)\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAeJT7ZJ2YWe"
      },
      "source": [
        "## P - value\n",
        "model = RandomForestClassifier(n_estimators=8,max_depth=9)\n",
        "AUC_metric = make_scorer(roc_auc_score)\n",
        "g_mean_metric = make_scorer(geometric_mean_score)\n",
        "_, _, pvalue = permutation_test_score(model, X, Y, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "_, _, pvalue2 = permutation_test_score(model, X, Y, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "print(pvalue)\n",
        "print(pvalue2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIFVaE1d1w84"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcRpoykhIjd9"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score,LeaveOneOut\n",
        "from statistics import mean as mean\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "Specificities = []\n",
        "\n",
        "for i in range(200):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold,y_train_fold = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    model = LogisticRegression(class_weight='balanced')\n",
        "    model.fit(X_train_fold,y_train_fold)\n",
        "    pt = model.predict(X_val_fold)\n",
        "    # for i in range(len(pt)):\n",
        "    #   if pt[i]> float(1/2):\n",
        "    #     pt[i] = 1\n",
        "    #   else:\n",
        "    #     pt[i] = 0\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "    Specificities.append(specificity)\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8KvkGxaIjn4"
      },
      "source": [
        "## p value\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "AUC_metric = make_scorer(roc_auc_score)\n",
        "g_mean_metric = make_scorer(geometric_mean_score)\n",
        "_, _, pvalue = permutation_test_score(model, X, Y, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "_, _, pvalue2 = permutation_test_score(model, X, Y, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "print(pvalue)\n",
        "print(pvalue2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlKvv6QZ1xFx"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy_vN47_2JuW"
      },
      "source": [
        "# K-fold\n",
        "from statistics import mean as mean\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import svm\n",
        "\n",
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "Specificities = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold,y_train_fold = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    model = svm.SVC()\n",
        "    model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "    pt = model.predict(X_val_fold)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "    Specificities.append(specificity)\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFClykrZJsX1"
      },
      "source": [
        "## p value \n",
        "from sklearn import svm\n",
        "model = svm.SVC()\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "AUC_metric = make_scorer(roc_auc_score)\n",
        "g_mean_metric = make_scorer(geometric_mean_score)\n",
        "# _, _, pvalue = permutation_test_score(model, X, Y, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "# print(pvalue)\n",
        "_, _, pvalue2 = permutation_test_score(model, X, Y, scoring=g_mean_metric, cv=cv, n_permutations=100)\n",
        "print(pvalue2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0WItGWf1xO1"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7labjgcb2Kps"
      },
      "source": [
        "### \"Wide\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNbIyp7-2TMf"
      },
      "source": [
        "# K-fold\n",
        "from statistics import mean as mean\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "Specificities = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold_resample,y_train_fold_resample = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    model = MLPClassifier(hidden_layer_sizes=(512, 512, 512), random_state=1)\n",
        "\n",
        "    model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "    pt = model.predict(X_val_fold)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "    Specificities.append(specificity)\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rK9ak0VN3xL"
      },
      "source": [
        "## p value \n",
        "from sklearn.neural_network import MLPClassifier\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "model = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(512, 512, 512), random_state=1)\n",
        "AUC_metric = make_scorer(roc_auc_score)\n",
        "g_mean_metric = make_scorer(geometric_mean_score)\n",
        "# _, _, pvalue = permutation_test_score(model, X, Y, scoring=AUC_metric, cv=cv, n_permutations=1000, n_jobs=-1)\n",
        "# print(pvalue)\n",
        "_, _, pvalue2 = permutation_test_score(model, X, Y, scoring=g_mean_metric, cv=cv, n_permutations=1000, n_jobs=-1)\n",
        "print(pvalue2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zpEHpZr2OWL"
      },
      "source": [
        "### \"Deep\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7D8ll2g2UNG"
      },
      "source": [
        "# K-fold\n",
        "from statistics import mean as mean\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "Specificities = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold_resample,y_train_fold_resample = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "\n",
        "    model = MLPClassifier(hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100), random_state=1)\n",
        "\n",
        "    model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "    pt = model.predict(X_val_fold)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "    Specificities.append(specificity)\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdv8GVuYOrPf"
      },
      "source": [
        "## p value \n",
        "from sklearn.neural_network import MLPClassifier\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "model = MLPClassifier(hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100))\n",
        "AUC_metric = make_scorer(roc_auc_score)\n",
        "g_mean_metric = make_scorer(geometric_mean_score)\n",
        "_, _, pvalue = permutation_test_score(model, X, Y, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "print(pvalue)\n",
        "_, _, pvalue2 = permutation_test_score(model, X, Y, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "print(pvalue2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvpilg3r2Ovk"
      },
      "source": [
        "### \"Middle\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpxypZMU2UrN"
      },
      "source": [
        "# K-fold\n",
        "from statistics import mean as mean\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "Specificities = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold_resample,y_train_fold_resample = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    \n",
        "    model = MLPClassifier(hidden_layer_sizes=(512, 256, 128, 64, 64), random_state=1, max_iter=400)\n",
        "\n",
        "    model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "    pt = model.predict(X_val_fold)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "    Specificities.append(specificity)\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRX6biH-OsK7"
      },
      "source": [
        "## p value\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "model = MLPClassifier(hidden_layer_sizes=(512, 256, 128, 64, 64), random_state=1, max_iter=400)\n",
        "AUC_metric = make_scorer(roc_auc_score)\n",
        "g_mean_metric = make_scorer(geometric_mean_score)\n",
        "_, _, pvalue = permutation_test_score(model, X, Y, scoring=AUC_metric, cv=cv, n_permutations=1000, n_jobs=-1)\n",
        "print(pvalue)\n",
        "_, _, pvalue2 = permutation_test_score(model, X, -Y, scoring=g_mean_metric, cv=cv, n_permutations=1000, n_jobs=-1)\n",
        "print(pvalue2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqYUIa0j1xXI"
      },
      "source": [
        "## kNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h09YXd7Z1sGm"
      },
      "source": [
        "# K-fold\n",
        "from statistics import mean as mean\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "for j in [3,5,7,9,11]:\n",
        "  Precisions = []\n",
        "  Recalls = []\n",
        "  F1s = []\n",
        "  G_means = []\n",
        "  accuracy = []\n",
        "  AUC = []\n",
        "  Specificities = []\n",
        "\n",
        "  for i in range(500):\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "    for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "      X_train_fold_resample,y_train_fold_resample = X[train_fold_index], Y[train_fold_index]\n",
        "      X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "\n",
        "      model = KNeighborsClassifier(n_neighbors=j)\n",
        "\n",
        "      model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "      pt = model.predict(X_val_fold)\n",
        "\n",
        "      tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "      specificity = tn / (tn+fp)\n",
        "      Specificities.append(specificity)\n",
        "      Precisions.append(precision_score(y_val_fold,pt))\n",
        "      Recalls.append(recall_score(y_val_fold,pt))\n",
        "      F1s.append(f1_score(y_val_fold,pt))\n",
        "      G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "      accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "      AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "  print(\"k = \"+ str(j))\n",
        "  print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "  print('Sensitivity/Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "  print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "  print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "  print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "  print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "  print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVCDiqGDPzMY"
      },
      "source": [
        "## p value \n",
        "for j in [3,5,7,9,11]:\n",
        "  model = KNeighborsClassifier(n_neighbors=j)\n",
        "  AUC_metric = make_scorer(roc_auc_score)\n",
        "  g_mean_metric = make_scorer(geometric_mean_score)\n",
        "  _, _, pvalue = permutation_test_score(model, X, Y, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "  _, _, pvalue2 = permutation_test_score(model, X, Y, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "  print(\"k = %i, p-value (AUC): %f, p-value (gmean) %f\"% (j, pvalue, pvalue2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wM_93EZ_gzG"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1_cjqjJOPgM"
      },
      "source": [
        "# K-fold\n",
        "from statistics import mean as mean\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "Precisions = []\n",
        "Recalls = []\n",
        "Specificities = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold,y_train_fold = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    model = XGBClassifier(max_depth=3, n_estimators=25, scale_pos_weight=.2)\n",
        "    model.fit(X_train_fold,y_train_fold)\n",
        "    pt = model.predict(X_val_fold)\n",
        "\n",
        "    #print(\"confusion_matrix:\")\n",
        "    #print(confusion_matrix(y_val_fold,pt))\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    Specificities.append(tn / (tn+fp))\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision - Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall - Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiOLhjfc_YDL"
      },
      "source": [
        "## XGBoost with Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_-dgmOyPI7U"
      },
      "source": [
        "# K-fold\n",
        "\n",
        "cv1 = StratifiedKFold(n_splits=3, random_state=12, shuffle=True)\n",
        "\n",
        "Precisons = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "\n",
        "cc2 = ClusterCentroids(random_state=12)\n",
        "print(X.shape,Y.shape)\n",
        "X_under, Y_under = cc2.fit_resample(X,Y)\n",
        "print(X_under.shape,Y_under.shape)\n",
        "\n",
        "for train_fold_index, val_fold_index in cv1.split(X_under,Y_under):\n",
        "  X_train_fold,y_train_fold = X_under[train_fold_index], Y_under[train_fold_index]\n",
        "  X_val_fold, y_val_fold = X_under[val_fold_index], Y_under[val_fold_index]\n",
        "\n",
        "  model = XGBClassifier(n_estimators=32, max_depth=3, scale_pos_weight=.2875)\n",
        "  model.fit(X_train_fold,y_train_fold)\n",
        "  pt = model.predict(X_val_fold)\n",
        "\n",
        "  #print(\"confusion_matrix:\")\n",
        "  #print(confusion_matrix(y_val_fold,pt))\n",
        "  tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "  specificity = tn / (tn+fp)\n",
        "  Specificities.append(specificity)\n",
        "  Precisons.append(precision_score(y_val_fold,pt))\n",
        "  Recalls.append(recall_score(y_val_fold,pt))\n",
        "  F1s.append(f1_score(y_val_fold,pt))\n",
        "  G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "  accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision: ',mean(Precisons))\n",
        "print('Recall: ',mean(Recalls))\n",
        "print('F1: ',mean(F1s))\n",
        "print('G_mean: ',mean(G_means))\n",
        "print('accuracy: ', mean(accuracy))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1572MnVE_WWk"
      },
      "source": [
        "## Oversampling for XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSf2DvzPY6WR"
      },
      "source": [
        "### SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CHpgVin33Kg"
      },
      "source": [
        "# K-fold\n",
        "from statistics import mean as mean\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "Specificities = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold,y_train_fold = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    smoter = SMOTE()\n",
        "    X_train_fold_resample, y_train_fold_resample = smoter.fit_resample(X_train_fold,y_train_fold)\n",
        "    model = XGBClassifier(max_depth=3, n_estimators=11, scale_pos_weight=.25)\n",
        "    model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "    pt = model.predict(X_val_fold)\n",
        "\n",
        "    #print(\"confusion_matrix:\")\n",
        "    #print(confusion_matrix(y_val_fold,pt))\n",
        "    tn, fp, fn, tp = confusion_matrix(y_val_fold, pt).ravel()\n",
        "    specificity = tn / (tn+fp)\n",
        "    Specificities.append(specificity)\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %f Standard Deviation: %f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Sensitivity/Recall- Mean:  %f Standard Deviation: %f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(Specificities), statistics.pstdev(Specificities)))\n",
        "print('F1- Mean:  %f Standard Deviation: %f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %f Standard Deviation: %f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %f Standard Deviation: %f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %f Standard Deviation: %f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jxxkgaz6WZ3"
      },
      "source": [
        "### Random Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQHrsMKnXtwJ"
      },
      "source": [
        "# K-fold\n",
        "from statistics import mean as mean\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "Precisions = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "AUC = []\n",
        "\n",
        "for i in range(500):\n",
        "  cv = StratifiedKFold(n_splits=3, shuffle=True)\n",
        "  for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "    X_train_fold,y_train_fold = X[train_fold_index], Y[train_fold_index]\n",
        "    X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "    ros = RandomOverSampler()\n",
        "    X_train_fold_resample, y_train_fold_resample = ros.fit_resample(X_train_fold,y_train_fold)\n",
        "    model = XGBClassifier(n_estimators=11, max_depth=3, scale_pos_weight=.25)\n",
        "    model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "    pt = model.predict(X_val_fold)\n",
        "\n",
        "    #print(\"confusion_matrix:\")\n",
        "    #print(confusion_matrix(y_val_fold,pt))\n",
        "    Precisions.append(precision_score(y_val_fold,pt))\n",
        "    Recalls.append(recall_score(y_val_fold,pt))\n",
        "    F1s.append(f1_score(y_val_fold,pt))\n",
        "    G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "    accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "    AUC.append(roc_auc_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision- Mean:  %.3f Standard Deviation: %.3f' % (mean(Precisions), statistics.pstdev(Precisions)))\n",
        "print('Recall- Mean:  %.3f Standard Deviation: %.3f' % (mean(Recalls), statistics.pstdev(Recalls)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(F1s), statistics.pstdev(F1s)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(G_means), statistics.pstdev(G_means)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(accuracy), statistics.pstdev(accuracy)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(AUC), statistics.pstdev(AUC)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SFjCCpobmmo"
      },
      "source": [
        "# Metrics for Naive Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC5SaeR5MlzQ"
      },
      "source": [
        "## Majority Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1m6soupM54z"
      },
      "source": [
        "# Naive Classifier \n",
        "## Predicts the Majority (Mucinous) Class\n",
        "## Source: https://machinelearningmastery.com/how-to-develop-and-evaluate-naive-classifier-strategies-using-probability/\n",
        "##         https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics \n",
        "\n",
        "# predict the majority class\n",
        "def majority_class(y):\n",
        "\treturn mode(y)[0]\n",
        "\n",
        "# make predictions\n",
        "yhat = [1 for _ in range(len(Y))]\n",
        "print(yhat)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y, yhat).ravel()\n",
        "\n",
        "\n",
        "# calculate Metrics\n",
        "print('F1 : %.3f' % f1_score(Y, yhat))\n",
        "print('Recall : %.3f' % recall_score(Y,yhat))\n",
        "print('Precision : %.3f' % precision_score(Y,yhat))\n",
        "print('Specificity : %.3f' % (tn/(tn+fp)))\n",
        "print('ROC: %.3f' % roc_auc_score(Y, yhat))\n",
        "print('G-Mean : %.3f' % geometric_mean_score(Y,yhat))\n",
        "print('accuracy : %.3f' % accuracy_score(Y,yhat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1FNR9Gpb3CL"
      },
      "source": [
        "## Minority Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "matJ-7UccBkp"
      },
      "source": [
        "# predict the majority class\n",
        "def majority_class(y):\n",
        "\treturn mode(y)[0]\n",
        "\n",
        "# make predictions\n",
        "yhat = [0 for _ in range(len(Y))] #Hardcoded for our model's distribution\n",
        "print(yhat)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y, yhat).ravel()\n",
        "\n",
        "# calculate Metrics\n",
        "print('F1 : %.3f' % f1_score(Y, yhat))\n",
        "print('Recall : %.3f' % recall_score(Y,yhat))\n",
        "print('Precision : %.3f' % precision_score(Y,yhat))\n",
        "print('Specificity : %.3f' % (tn/(tn+fp)))\n",
        "print('ROC: %.3f' % roc_auc_score(Y, yhat))\n",
        "print('G-Mean : %.3f' % geometric_mean_score(Y,yhat))\n",
        "print('accuracy : %.3f' % accuracy_score(Y,yhat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq08zkQcb3Ni"
      },
      "source": [
        "## Random Guesser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LFUVOvkcBGO"
      },
      "source": [
        "from statistics import mean as mean\n",
        "dummy_clf = DummyClassifier(strategy=\"uniform\")\n",
        "dummy_clf.fit(X, Y)\n",
        "y_predicted = dummy_clf.predict(X)\n",
        "\n",
        "f1= []\n",
        "rcll = []\n",
        "prc = []\n",
        "gmean = []\n",
        "acc = []\n",
        "spec = []\n",
        "roc = []\n",
        "\n",
        "for i in range(1000):\n",
        "  y_predicted = dummy_clf.predict(X)\n",
        "  f1.append(f1_score(Y, y_predicted))\n",
        "  rcll.append(recall_score(Y,y_predicted))\n",
        "  prc.append(precision_score(Y,y_predicted))\n",
        "  gmean.append(geometric_mean_score(Y,y_predicted))\n",
        "  acc.append(accuracy_score(Y,y_predicted))\n",
        "  tn, fp, fn, tp = confusion_matrix(Y, y_predicted).ravel()\n",
        "  spec.append(tn/(tn+fp))\n",
        "  roc.append(roc_auc_score(Y,y_predicted))\n",
        "\n",
        "print('Precision - Mean:  %.3f Standard Deviation: %.3f' % (mean(prc), statistics.pstdev(prc)))\n",
        "print('Sensitivity/Recall - Mean:  %.3f Standard Deviation: %.3f' % (mean(rcll), statistics.pstdev(rcll)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(spec), statistics.pstdev(spec)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(f1), statistics.pstdev(f1)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(gmean), statistics.pstdev(gmean)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(acc), statistics.pstdev(acc)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(roc), statistics.pstdev(roc)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQEY83jib3Yh"
      },
      "source": [
        "## Stratified Guesser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztF5AgvDcAmf"
      },
      "source": [
        "from statistics import mean as mean\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
        "dummy_clf.fit(X, Y)\n",
        "\n",
        "f1= []\n",
        "rcll = []\n",
        "prc = []\n",
        "gmean = []\n",
        "acc = []\n",
        "spec = []\n",
        "roc = []\n",
        "\n",
        "for i in range(1000):\n",
        "  y_predicted = dummy_clf.predict(X)\n",
        "  f1.append(f1_score(Y, y_predicted))\n",
        "  rcll.append(recall_score(Y,y_predicted))\n",
        "  prc.append(precision_score(Y,y_predicted))\n",
        "  gmean.append(geometric_mean_score(Y,y_predicted))\n",
        "  acc.append(accuracy_score(Y,y_predicted))\n",
        "  tn, fp, fn, tp = confusion_matrix(Y, y_predicted).ravel()\n",
        "  spec.append(tn/(tn+fp))\n",
        "  roc.append(roc_auc_score(Y,y_predicted))\n",
        "\n",
        "print('Precision - Mean:  %.3f Standard Deviation: %.3f' % (mean(prc), statistics.pstdev(prc)))\n",
        "print('Sensitivity/Recall - Mean:  %.3f Standard Deviation: %.3f' % (mean(rcll), statistics.pstdev(rcll)))\n",
        "print('Specificity - Mean:  %.3f Standard Deviation: %.3f' % (mean(spec), statistics.pstdev(spec)))\n",
        "print('F1- Mean:  %.3f Standard Deviation: %.3f' % (mean(f1), statistics.pstdev(f1)))\n",
        "print('G_mean- Mean:  %.3f Standard Deviation: %.3f' % (mean(gmean), statistics.pstdev(gmean)))\n",
        "print('Accuracy- Mean:  %.3f Standard Deviation: %.3f' % (mean(acc), statistics.pstdev(acc)))\n",
        "print('AUC Score- Mean:  %.3f Standard Deviation: %.3f' % (mean(roc), statistics.pstdev(roc)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47MNyx1Iq42W"
      },
      "source": [
        "# P - Values for Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oTt3Wy9Aq4Tx"
      },
      "source": [
        "# Datasets\n",
        "## Full Feature Set\n",
        "df = pd.read_csv(DATASET_LOCATION)\n",
        "x_full = df.drop(\"mucinous\", axis=1); #Entire dataset\n",
        "Y_full = df[\"mucinous\"].copy()\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_full = scaler.fit_transform(x_full)\n",
        "\n",
        "#Import Texture-Only Feature Set\n",
        "df = pd.read_csv(DATASET_LOCATION)\n",
        "x_texture = df.drop(\"mucinous\", axis=1); #Entire dataset\n",
        "Y_texture = df[\"mucinous\"].copy();\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_texture = scaler.fit_transform(x_texture)\n",
        "\n",
        "# Models\n",
        "## Naive\n",
        "### Majority, Minority, random, stratified\n",
        "majority = DummyClassifier(strategy='constant', constant=1) #strategy='most_frequent'\n",
        "minority = DummyClassifier(strategy='constant', constant=0)\n",
        "random = DummyClassifier(strategy='uniform', constant=1)\n",
        "stratified = DummyClassifier(strategy='stratified', constant=1)\n",
        "random.fit(X_full, Y_full)\n",
        "stratified.fit(X_full, Y_full)\n",
        "\n",
        "## ML\n",
        "### SMOTE Full Feature, SMOTE Texture-Only, XGBoost Full, XGBoost Texture-only\n",
        "XGBoost = XGBClassifier(n_estimators=11, max_depth=3, scale_pos_weight=.25)\n",
        "SMOTE_XGBoost = Pipeline([\n",
        "        ('sampling', SMOTE()),\n",
        "        ('classification', XGBoost)\n",
        "    ])\n",
        "\n",
        "# Scoring\n",
        "## Setup\n",
        "cv = StratifiedKFold(n_splits=5, random_state=12, shuffle=True)\n",
        "AUC_metric = make_scorer(roc_auc_score)\n",
        "g_mean_metric = make_scorer(geometric_mean_score)\n",
        "p_values_AUC = {}\n",
        "p_values_g_mean = {}\n",
        "titles = [\"AUC p-value\", \"G-Mean p-value\"]\n",
        "\n",
        "## AUC\n",
        "_, _, pvalue = permutation_test_score(majority, X_full, Y_full, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"majority\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(minority, X_full, Y_full, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"minority\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(random, X_full, Y_full, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"random\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(stratified, X_full, Y_full, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"stratified\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(XGBoost, X_full, Y_full, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"XGBoost_Full\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(SMOTE_XGBoost, X_full, Y_full, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"SMOTE_Full\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(XGBoost, X_texture, Y_texture, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"XGBoost_Texture\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(SMOTE_XGBoost, X_texture, Y_texture, scoring=AUC_metric, cv=cv, n_permutations=1000)\n",
        "p_values_AUC[\"SMOTE_Texture\"] = pvalue\n",
        "\n",
        "## G - Mean\n",
        "_, _, pvalue = permutation_test_score(majority, X_full, Y_full, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"majority\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(minority, X_full, Y_full, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"minority\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(random, X_full, Y_full, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"random\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(stratified, X_full, Y_full, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"stratified\"] = pvalue\n",
        "score, _, pvalue = permutation_test_score(XGBoost, X_full, Y_full, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"XGBoost_Full\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(SMOTE_XGBoost, X_full, Y_full, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"SMOTE_Full\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(XGBoost, X_texture, Y_texture, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"XGBoost_Texture\"] = pvalue\n",
        "_, _, pvalue = permutation_test_score(SMOTE_XGBoost, X_texture, Y_texture, scoring=g_mean_metric, cv=cv, n_permutations=1000)\n",
        "p_values_g_mean[\"SMOTE_Texture\"] = pvalue\n",
        "\n",
        "# Output Table\n",
        "print(\"AUC\")\n",
        "print(p_values_AUC)\n",
        "print(\"G-Mean\")\n",
        "print(p_values_g_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkQr6Ld6nJ5Z"
      },
      "source": [
        "# Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASJWSwCZq4pe"
      },
      "source": [
        "## Plot Decision Bounds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kuxons1wmF9B"
      },
      "source": [
        "#https://pierpaolo28.github.io/Projects/project6.html\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from itertools import product\n",
        "pca = PCA(n_components=2,svd_solver='full')\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "X_reduced, X_test_reduced, Y_Train, Y_Test = train_test_split(X_pca, Y, test_size=.2,shuffle=True,stratify=Y)\n",
        "\n",
        "reduced_data = X_reduced\n",
        "\n",
        "trainedmodel = XGBClassifier(n_estimators=7, max_depth=3, scale_pos_weight=.25).fit(reduced_data,Y_Train)\n",
        "\n",
        "x_min, x_max = reduced_data[:, 0].min() - .5, reduced_data[:, 0].max() + .5\n",
        "y_min, y_max = reduced_data[:, 1].min() - .5, reduced_data[:, 1].max() + .5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
        "                     np.arange(y_min, y_max, 0.1))\n",
        "\n",
        "Z = trainedmodel.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "arg_0 = np.where(Y_Train == 0)\n",
        "arg_1 = np.where(Y_Train == 1)\n",
        "\n",
        "plt.figure(figsize=(7.5,5))\n",
        "plt.contourf(xx, yy, Z,cmap=plt.cm.coolwarm, alpha=0.4)\n",
        "plt.scatter(reduced_data[arg_1, 0], reduced_data[arg_1, 1],\n",
        "                              s=20, edgecolor='k', marker='^', label='Mucinous', c='purple')\n",
        "plt.scatter(reduced_data[arg_0, 0], reduced_data[arg_0, 1],\n",
        "                              s=20, edgecolor='k', c='yellow', label='Non-mucinous')\n",
        "plt.title('XGBoost - Mucinous Classifier')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUvop-yJoPBF"
      },
      "source": [
        "## Shap Model Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl4EDYDNoRYD"
      },
      "source": [
        "#Import DataFrame from .csv file\n",
        "df = pd.read_csv(DATASET_LOCATION)\n",
        "\n",
        "#Creating labels\n",
        "x = df.drop(\"mucinous\", axis=1); #Entire dataset\n",
        "Y = df[\"mucinous\"].copy();\n",
        "feature_cols = x.columns\n",
        "\n",
        "#Scale values from 0 to 1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X = scaler.fit_transform(x)\n",
        "\n",
        "model = XGBClassifier(max_depth=3, n_estimators=11, scale_pos_weight=.25)\n",
        "model.fit(X,Y)\n",
        "# explain the model's predictions using SHAP\n",
        "# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X)\n",
        "\n",
        "# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
        "shap.summary_plot(shap_values, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2Ro9B23wu3g"
      },
      "source": [
        "#Import DataFrame from .csv file\n",
        "df = pd.read_csv(DATASET_LOCATION)\n",
        "\n",
        "#Creating labels\n",
        "x = df.drop(\"mucinous\", axis=1); #Entire dataset\n",
        "Y = df[\"mucinous\"].copy();\n",
        "feature_cols = x.columns\n",
        "\n",
        "#Scale values from 0 to 1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X = scaler.fit_transform(x)\n",
        "print(X.shape)\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=12,test_size=.2,shuffle=True,stratify=Y)\n",
        "#print(X_train.shape, X_test.shape)\n",
        "\n",
        "model = XGBClassifier(max_depth=3, n_estimators=8, scale_pos_weight=.25)\n",
        "model.fit(X,Y)\n",
        "# explain the model's predictions using SHAP\n",
        "# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X)\n",
        "\n",
        "# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
        "shap.summary_plot(shap_values, x)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-a4DZrHo46j"
      },
      "source": [
        "# load JS visualization code to notebook\n",
        "shap.initjs()\n",
        "\n",
        "model = XGBClassifier(max_depth=3, n_estimators=11, scale_pos_weight=.25)\n",
        "model.fit(X,Y)\n",
        "\n",
        "# explain the model's predictions using SHAP\n",
        "# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X)\n",
        "\n",
        "# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
        "shap.force_plot(explainer.expected_value, shap_values[0,:], x.iloc[0,:], matplotlib=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50SDuqQx0Tel"
      },
      "source": [
        "## Curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg-vk0JJ0RT2"
      },
      "source": [
        "### PR Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76fcAAT6wCy4"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "from numpy import interp\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "FOLDS = 10\n",
        "\n",
        "f, axes = plt.subplots(figsize=(10,10))\n",
        "k_fold = StratifiedKFold(n_splits=FOLDS, random_state=12, shuffle=True)\n",
        "results = pd.DataFrame(columns=['training_score', 'test_score'])\n",
        "\n",
        "\n",
        "y_realtot = []\n",
        "y_probatot = []\n",
        "\n",
        "precision_arraytot = []\n",
        "threshold_arraytot=[]\n",
        "recall_arraytot = np.linspace(0, 1, 100)\n",
        "\n",
        "for j in range(10):\n",
        "  y_real = []\n",
        "  y_proba = []\n",
        "\n",
        "  precision_array = []\n",
        "  threshold_array=[]\n",
        "  recall_array = np.linspace(0, 1, 100)\n",
        "  for i, (train_index, test_index) in enumerate(k_fold.split(X,Y)):\n",
        "    predictor = XGBClassifier(n_estimators=32, max_depth=3, scale_pos_weight=.2875)\n",
        "      \n",
        "    X_train_fold,y_train_fold = X[train_index], Y[train_index]\n",
        "    X_val_fold, y_val_fold = X[test_index], Y[test_index]\n",
        "    smoter = SMOTE(random_state=12)\n",
        "    X_train_fold_resample, y_train_fold_resample = smoter.fit_resample(X_train_fold,y_train_fold)\n",
        "      \n",
        "      \n",
        "    predictor.fit(X_train_fold_resample, y_train_fold_resample)\n",
        "    pred_proba = predictor.predict_proba(X_val_fold)\n",
        "    precision_fold, recall_fold, thresh = precision_recall_curve(y_val_fold, pred_proba[:,1])\n",
        "    precision_fold, recall_fold, thresh = precision_fold[::-1], recall_fold[::-1], thresh[::-1]  # reverse order of results\n",
        "    thresh = np.insert(thresh, 0, 1.0)\n",
        "    precision_array = interp(recall_array, recall_fold, precision_fold)\n",
        "    threshold_array = interp(recall_array, recall_fold, thresh)\n",
        "    pr_auc = auc(recall_array, precision_array)\n",
        "\n",
        "    lab_fold = 'Fold %d AUC=%.4f' % (i+1, pr_auc)\n",
        "    #plt.plot(recall_fold, precision_fold, alpha=0.3, label=lab_fold)\n",
        "    y_real.append(y_val_fold)\n",
        "    y_proba.append(pred_proba[:,1])\n",
        "\n",
        "  y_real = numpy.concatenate(y_real)\n",
        "  y_proba = numpy.concatenate(y_proba)\n",
        "  precision, recall, _ = precision_recall_curve(y_real, y_proba)\n",
        "  lab_foldtot = 'PR %d AUC=%.4f' % (j+1, pr_auc)\n",
        "  plt.plot(recall, precision, marker='.' ,alpha=0.3, label=lab_foldtot)\n",
        "  y_realtot.append(y_real)\n",
        "  y_probatot.append(y_proba)\n",
        "  precision_arraytot = interp(recall_array, recall, precision)\n",
        "  threshold_arraytot = interp(recall_array, recall, precision)\n",
        " #plt.plot(recall_fold, precision_fold, alpha=0.3, label=lab_fold)\n",
        "#finsih 10 iterations.\n",
        "y_realtot = numpy.concatenate(y_realtot)\n",
        "y_probatot= numpy.concatenate(y_probatot)\n",
        "precision, recall, _ = precision_recall_curve(y_realtot, y_probatot)\n",
        "lab = 'Overall AUC=%.4f' % (auc(recall, precision))\n",
        "\n",
        "plt.plot(recall, precision, marker='.', lw=2,color='red', label=lab)\n",
        "plt.legend(loc='lower left', fontsize=18)\n",
        "\n",
        "lab = 'Overall AUC=%.4f' % (auc(recall, precision))\n",
        "mean_precision = np.mean(precision)\n",
        "mean_recall = np.mean(recall)\n",
        "std_precision = np.std(precision)\n",
        "print (\"mean of precision: \" )\n",
        "print (mean_precision )\n",
        "\n",
        "print (\"Std Dev of precision: \")\n",
        "print ( std_precision )\n",
        "# print (\"mean of recall: \" )\n",
        "# print (mean_precision )\n",
        "axes.set_title('10 Indenpendent PR Curves of Random Forest Over 10 Folds Cross Validation', fontsize=18)\n",
        "\n",
        "plt.fill_between(recall, precision + std_precision, precision - std_precision, alpha=0.3, linewidth=0, color='grey')\n",
        "plt.xlabel(\"Recall\", fontsize=18)\n",
        "plt.ylabel(\"Precision\", fontsize=18)\n",
        "plt.ylim((0,1))\n",
        "plt.xlim((0,1))\n",
        "plt.show()\n",
        "\n",
        "f.savefig('result.png')\n",
        "print (precision)\n",
        "print (recall)\n",
        "print (_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rhGEp140nYK"
      },
      "source": [
        "### ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-RpAgWplpXf"
      },
      "source": [
        " ## ROC Curve for 5-Fold Cross Validation with SMOTE oversampling \n",
        " # Source: https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/auto_examples/plot_roc_crossval.html\n",
        "\n",
        "# #############################################################################\n",
        "# Run classifier with cross-validation and plot ROC curves\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/CT Analysis/Data Sets/mucinous_processed.csv')\n",
        "\n",
        "#Creating labels\n",
        "full_x = df.drop(\"mucinous\", axis=1); #Entire dataset\n",
        "full_Y = df[\"mucinous\"].copy();\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "full_x = scaler.fit_transform(full_x)\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/CT Analysis/Data Sets/texture_feature_set_mucinous_processed.csv')\n",
        "\n",
        "#Creating labels\n",
        "texture_x = df.drop(\"mucinous\", axis=1); #Entire dataset\n",
        "texture_Y = df[\"mucinous\"].copy();\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "texture_x = scaler.fit_transform(texture_x)\n",
        "\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "#classifier = RandomForestClassifier(n_estimators=25,max_depth=20, class_weight='balanced')\n",
        "plt.rcParams[\"figure.figsize\"] = [14,10]\n",
        "tprs_full = []\n",
        "aucs_full = []\n",
        "mean_fpr_full = np.linspace(0, 1, 100)\n",
        "tprs_text = []\n",
        "aucs_text = []\n",
        "mean_fpr_text = np.linspace(0, 1, 100)\n",
        "fig, full = plt.subplots()\n",
        "fig, text = plt.subplots()\n",
        "fig, both = plt.subplots()\n",
        "\n",
        "for j in range(500):\n",
        "  for i, (train_fold_index, val_fold_index) in enumerate(cv.split(full_x, full_Y)):\n",
        "    X_train_full,y_train_full = full_x[train_fold_index], full_Y[train_fold_index]\n",
        "    X_val_full, y_val_full = full_x[val_fold_index], full_Y[val_fold_index]\n",
        "    \n",
        "    X_train_text,y_train_text = texture_x[train_fold_index], texture_Y[train_fold_index]\n",
        "    X_val_text, y_val_text = texture_x[val_fold_index], texture_Y[val_fold_index]\n",
        "\n",
        "    classifier_full = XGBClassifier(n_estimators=11, max_depth=3, scale_pos_weight=.25)\n",
        "    classifier_full.fit(X_train_full,y_train_full)\n",
        "    classifier_text = XGBClassifier(n_estimators=8, max_depth=3, scale_pos_weight=.25)\n",
        "    classifier_text.fit(X_train_text,y_train_text)\n",
        "\n",
        "    y_scores_full = classifier_full.predict_proba(X_val_full)[:, 1]\n",
        "    fpr_full, tpr_full, thresholds_full = metrics.roc_curve(y_val_full, classifier_full.predict_proba(X_val_full)[:, 1])\n",
        "    y_scores_text = classifier_text.predict_proba(X_val_text)[:, 1]\n",
        "    fpr_text, tpr_text, thresholds_text = metrics.roc_curve(y_val_text, classifier_text.predict_proba(X_val_text)[:, 1])\n",
        "\n",
        "    interp_tpr_full = np.interp(mean_fpr_full, fpr_full, tpr_full)\n",
        "    interp_tpr_full[0] = 0.0\n",
        "    tprs_full.append(interp_tpr_full)\n",
        "    aucs_full.append(metrics.auc(fpr_full, tpr_full))\n",
        "\n",
        "    interp_tpr_text = np.interp(mean_fpr_text, fpr_text, tpr_text)\n",
        "    interp_tpr_text[0] = 0.0\n",
        "    tprs_text.append(interp_tpr_text)\n",
        "    aucs_text.append(metrics.auc(fpr_text, tpr_text))\n",
        "    \n",
        "### Full Feature Plot\n",
        "full.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
        "        label='Chance', alpha=.8)\n",
        "\n",
        "mean_tpr_full = np.mean(tprs_full, axis=0)\n",
        "mean_tpr_full[-1] = 1.0\n",
        "mean_auc_full = auc(mean_fpr_full, mean_tpr_full)\n",
        "std_auc_full = np.std(aucs_full)\n",
        "full.plot(mean_fpr_full, mean_tpr_full, color='b',\n",
        "        label=r'Mean ROC of Full Feature Set(AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc_full, std_auc_full),\n",
        "        lw=2, alpha=.8)\n",
        "\n",
        "std_tpr_full = np.std(tprs_full, axis=0)\n",
        "tprs_upper_full = np.minimum(mean_tpr_full + std_tpr_full, 1)\n",
        "tprs_lower_full = np.maximum(mean_tpr_full - std_tpr_full, 0)\n",
        "full.fill_between(mean_fpr_full, tprs_lower_full, tprs_upper_full, color='blue', alpha=.1,\n",
        "                label=r'$\\pm$ 1 std. dev.')\n",
        "\n",
        "full.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
        "       title=\"Receiver operating characteristic\")\n",
        "full.legend(loc=\"lower right\")\n",
        "\n",
        "### Texture Only Plot\n",
        "text.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
        "        label='Chance', alpha=.8)\n",
        "mean_tpr_text = np.mean(tprs_text, axis=0)\n",
        "mean_tpr_text[-1] = 1.0\n",
        "mean_auc_text = auc(mean_fpr_text, mean_tpr_text)\n",
        "std_auc_text = np.std(aucs_text)\n",
        "text.plot(mean_fpr_text, mean_tpr_text, color='g',\n",
        "        label=r'Mean ROC of Texture Feature Set(AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc_text, std_auc_text),\n",
        "        lw=2, alpha=.8)\n",
        "\n",
        "std_tpr_text = np.std(tprs_text, axis=0)\n",
        "tprs_upper_text = np.minimum(mean_tpr_text + std_tpr_text, 1)\n",
        "tprs_lower_text = np.maximum(mean_tpr_text - std_tpr_text, 0)\n",
        "text.fill_between(mean_fpr_text, tprs_lower_text, tprs_upper_text, color='green', alpha=.1,\n",
        "                label=r'$\\pm$ 1 std. dev.')\n",
        "\n",
        "text.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
        "       title=\"Receiver operating characteristic\")\n",
        "text.legend(loc=\"lower right\")\n",
        "\n",
        "### Combined Plot\n",
        "## Full Features\n",
        "both.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
        "        label='Chance', alpha=.8)\n",
        "\n",
        "mean_tpr_full = np.mean(tprs_full, axis=0)\n",
        "mean_tpr_full[-1] = 1.0\n",
        "mean_auc_full = auc(mean_fpr_full, mean_tpr_full)\n",
        "std_auc_full = np.std(aucs_full)\n",
        "both.plot(mean_fpr_full, mean_tpr_full, color='b',\n",
        "        label=r'Mean ROC of Full Feature Set(AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc_full, std_auc_full),\n",
        "        lw=2, alpha=.8)\n",
        "\n",
        "std_tpr_full = np.std(tprs_full, axis=0)\n",
        "tprs_upper_full = np.minimum(mean_tpr_full + std_tpr_full, 1)\n",
        "tprs_lower_full = np.maximum(mean_tpr_full - std_tpr_full, 0)\n",
        "both.fill_between(mean_fpr_full, tprs_lower_full, tprs_upper_full, color='blue', alpha=.1,\n",
        "                label=r'$\\pm$ 1 std. dev.')\n",
        "\n",
        "both.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
        "       title=\"Receiver operating characteristic\")\n",
        "both.legend(loc=\"lower right\")\n",
        "\n",
        "## Texture Features\n",
        "mean_tpr_text = np.mean(tprs_text, axis=0)\n",
        "mean_tpr_text[-1] = 1.0\n",
        "mean_auc_text = auc(mean_fpr_text, mean_tpr_text)\n",
        "std_auc_text = np.std(aucs_text)\n",
        "both.plot(mean_fpr_text, mean_tpr_text, color='g',\n",
        "        label=r'Mean ROC of Texture Feature Set(AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc_text, std_auc_text),\n",
        "        lw=2, alpha=.8)\n",
        "\n",
        "std_tpr_text = np.std(tprs_text, axis=0)\n",
        "tprs_upper_text = np.minimum(mean_tpr_text + std_tpr_text, 1)\n",
        "tprs_lower_text = np.maximum(mean_tpr_text - std_tpr_text, 0)\n",
        "both.fill_between(mean_fpr_text, tprs_lower_text, tprs_upper_text, color='green', alpha=.2,\n",
        "                label=r'$\\pm$ 1 std. dev.')\n",
        "\n",
        "both.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
        "       title=\"Receiver operating characteristic\")\n",
        "both.legend(loc=\"lower right\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLkq9_6UaV2v"
      },
      "source": [
        "## Permutation Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90irGYfqfuVm"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import permutation_test_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "#Uses test 1 described here:\n",
        "# http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf\n",
        "\n",
        "# #############################################################################\n",
        "n_classes = np.unique(Y).size\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, random_state=12, shuffle=True)\n",
        "xgb =  XGBClassifier(n_estimators=32, max_depth=3, scale_pos_weight=.2875)\n",
        "metric=make_scorer(geometric_mean_score)\n",
        "\n",
        "score, permutation_scores, pvalue = permutation_test_score(\n",
        "    xgb,X, Y, scoring=metric, cv=cv, n_permutations=1000)\n",
        "\n",
        "print(\"Classification score %s (pvalue : %s)\" % (score, pvalue))\n",
        "\n",
        "# #############################################################################\n",
        "# View histogram of permutation scores\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.hist(permutation_scores, 20, label='Permutation scores',\n",
        "         edgecolor='black')\n",
        "ylim = plt.ylim()\n",
        "\n",
        "plt.plot(2 * [score], ylim, '--g', linewidth=3,\n",
        "         label='Classification Score'\n",
        "         ' (pvalue %s)' % pvalue)\n",
        "plt.plot(2 * [1. /n_classes], ylim, '--k', linewidth=3, label='Luck')\n",
        "#plt.plot(2 * [luck_new], ylim, '--k', linewidth=3, label='Luck')\n",
        "plt.ylim(ylim)\n",
        "plt.legend()\n",
        "plt.xlabel('Score')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwyOGmkpc9TW"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpUcD1IfgzJr"
      },
      "source": [
        "#Creating labels\n",
        "x1 = df2\n",
        "Y = df[\"mucinous\"].copy();\n",
        "feature_cols = x1.columns\n",
        "\n",
        "#Scale values from 0 to 1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X1 = scaler.fit_transform(x1)\n",
        "print(X1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vTyPWligzAS"
      },
      "source": [
        "#most improtant feature function\n",
        "\n",
        "def Important_fetures(mymodel,featuredict):\n",
        "    import numpy as np\n",
        "    import sklearn as sk\n",
        "    import sklearn.datasets as skd\n",
        "    import matplotlib.pyplot as plt\n",
        "    %matplotlib inline\n",
        "\n",
        "    importances = model.feature_importances_\n",
        "    indice = np.argsort(importances)[::-1]\n",
        "    indices = indice [:30]\n",
        "    \n",
        "    # Print the feature ranking\n",
        "    # print(\"Feature ranking:\")\n",
        "    num=0\n",
        "    with open(OUTPUT_LOCATION_OF_FEATURE_FILE, \"w\") as txt_file:\n",
        "      for f in indices:\n",
        "        indexname = f;\n",
        "        num+=1;\n",
        "        #print(\"%d. feature:  %s (%f)\" % (num, feature_cols[indexname], importances[indexname]))\n",
        "        if feature_cols[indexname] in featuredict:\n",
        "          featuredict[feature_cols[indexname]][0] += 1\n",
        "          featuredict[feature_cols[indexname]][1] += importances[indexname]\n",
        "        else:\n",
        "          featuredict[feature_cols[indexname]] = [1,importances[indexname]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylZcoJlLgzDE"
      },
      "source": [
        "# K-fold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score,LeaveOneOut\n",
        "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from statistics import mean\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "featuredict = {}\n",
        "\n",
        "for x in range(1000):\n",
        "\n",
        "        cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "        Precisons = []\n",
        "        Recalls = []\n",
        "        F1s = []\n",
        "        G_means = []\n",
        "\n",
        "        for train_fold_index, val_fold_index in cv.split(X,Y):\n",
        "          X_train_fold,y_train_fold = X[train_fold_index], Y[train_fold_index]\n",
        "          X_val_fold, y_val_fold = X[val_fold_index], Y[val_fold_index]\n",
        "          #smoter = SMOTE()\n",
        "          #X_train_fold_resample, y_train_fold_resample = smoter.fit_resample(X_train_fold,y_train_fold)\n",
        "          model = XGBClassifier(n_estimators=8, max_depth=3, scale_pos_weight=.25)\n",
        "          #model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "          model.fit(X_train_fold,y_train_fold)\n",
        "          pt = model.predict(X_val_fold)\n",
        "\n",
        "          Important_fetures(model,featuredict)\n",
        "\n",
        "          # print(\"confusion_matrix:\")\n",
        "          # print(confusion_matrix(y_val_fold,pt))\n",
        "          Precisons.append(precision_score(y_val_fold,pt))\n",
        "          Recalls.append(recall_score(y_val_fold,pt))\n",
        "          F1s.append(f1_score(y_val_fold,pt))\n",
        "          G_means.append(geometric_mean_score(y_val_fold,pt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vd8WAEWgzFp"
      },
      "source": [
        "#List ranked by average\n",
        "import operator\n",
        "import collections\n",
        "Avg = {}\n",
        "Ocurr = {}\n",
        "Tavg ={}\n",
        "for key in featuredict:\n",
        "  Avg[key] = [featuredict[key][1]/featuredict[key][0],featuredict[key][0]]\n",
        "  Ocurr[key] = featuredict[key][0]\n",
        "  Tavg[key] =  featuredict[key][1]/5000\n",
        "\n",
        "AvgRank = sorted(Avg.items(),key=lambda kv: kv[1][0],reverse=True)\n",
        "OcurrRank = sorted(Ocurr.items(),key=lambda x: x[1],reverse=True)\n",
        "TavRank = sorted(Tavg.items(),key=lambda kv: kv[1],reverse=True)\n",
        "\n",
        "sortedAvg = {}\n",
        "for i in AvgRank:\n",
        "  sortedAvg[i[0]] = [i[1][0],i[1][1]]\n",
        "\n",
        "Ocuurpd = pd.DataFrame.from_dict(OcurrRank)\n",
        "Avgdf = pd.DataFrame.from_dict(sortedAvg,orient='index',columns=['Avg.Value','Occurance'])\n",
        "Tavdf = pd.DataFrame.from_dict(TavRank)\n",
        "Ocuurpd.columns = ['Feature', 'Avg. Value']\n",
        "Avgdf.to_csv('Average feature Importance.CSV');\n",
        "Ocuurpd.to_csv('Occurance.CSV')\n",
        "Tavdf.to_csv('TSC.CSV')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE5aWmcQgzHz"
      },
      "source": [
        "a = 0 \n",
        "df2 = df\n",
        "for (columnName, columnData) in df.iteritems():\n",
        "  if columnName not in Avg:\n",
        "    a +=1\n",
        "    df2 = df2.drop(columnName, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k8FIL6agzMk"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score,LeaveOneOut\n",
        "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from statistics import mean\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, random_state=12, shuffle=True)\n",
        "\n",
        "Precisons = []\n",
        "Recalls = []\n",
        "F1s = []\n",
        "G_means = []\n",
        "accuracy = []\n",
        "\n",
        "\n",
        "for train_fold_index, val_fold_index in cv.split(X1,Y):\n",
        "  X_train_fold,y_train_fold = X1[train_fold_index], Y[train_fold_index]\n",
        "  X_val_fold, y_val_fold = X1[val_fold_index], Y[val_fold_index]\n",
        "  smoter = SMOTE(random_state=12)\n",
        "  X_train_fold_resample, y_train_fold_resample = smoter.fit_resample(X_train_fold,y_train_fold)\n",
        "  model = XGBClassifier(n_estimators=32, max_depth=3, scale_pos_weight=.2875)\n",
        "  model.fit(X_train_fold_resample,y_train_fold_resample)\n",
        "  pt = model.predict(X_val_fold)\n",
        "\n",
        "  print(\"confusion_matrix:\")\n",
        "  print(confusion_matrix(y_val_fold,pt))\n",
        "  Precisons.append(precision_score(y_val_fold,pt))\n",
        "  Recalls.append(recall_score(y_val_fold,pt))\n",
        "  F1s.append(f1_score(y_val_fold,pt))\n",
        "  G_means.append(geometric_mean_score(y_val_fold,pt))\n",
        "  accuracy.append(accuracy_score(y_val_fold,pt))\n",
        "\n",
        "print('Precision: ',mean(Precisons))\n",
        "print('Recall: ',mean(Recalls))\n",
        "print('F1: ',mean(F1s))\n",
        "print('G_mean: ',mean(G_means))\n",
        "print('Accuracy: ',mean(accuracy))\n",
        "print(AvgRank)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}